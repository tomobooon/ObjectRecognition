{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow1",
      "provenance": [],
      "mount_file_id": "15Nc_63uNoOXS9yNsvxg9yRCjyIgaUOFf",
      "authorship_tag": "ABX9TyOF4+bf7eNZ9iXCV6plGSeV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomobooon/ObjectRecognition/blob/main/tensorflow1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZG72kQqrc4I"
      },
      "source": [
        "#ディープラーニングによる物体検出\n",
        "https://note.com/navitime_tech/n/nae344375d0c9\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8twMcqgOuGeX"
      },
      "source": [
        "img_name = 'dog'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ciwnUVroU4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "img_path = \"./drive/MyDrive/imgdata/\" + img_name + \".jpg\"\n",
        "\n",
        "# 画像データの読み込み\n",
        "image = tf.io.read_file(img_path)\n",
        "image = tf.io.decode_jpeg(image)\n",
        "# image = tf.image.convert_image_dtype(image, tf.float32)  # 今回は正規化は不要\n",
        "image = tf.expand_dims(image, axis=0)\n",
        "\n",
        "# モデルをロード\n",
        "model = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\")\n",
        "\n",
        "# 推論を実行\n",
        "outputs = model(image)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0D6UzA2sjdT",
        "outputId": "aa6ccb48-b87f-4283-9bf2-8351fec6479f"
      },
      "source": [
        "\n",
        "boxes = outputs[\"detection_boxes\"][0]\n",
        "labels = outputs[\"detection_classes\"][0]\n",
        "scores = outputs[\"detection_scores\"][0]\n",
        "\n",
        "output_image = cv.imread(img_path)\n",
        "height, width = image.shape[1:3]\n",
        "\n",
        "print(labels)\n",
        "\n",
        "for box, label, score in zip(boxes, labels, scores):\n",
        "    # スコアが 0.5 より大きいものだけ抽出\n",
        "    if score <= 0.01:\n",
        "        continue\n",
        "\n",
        "    box = box * np.array([height, width, height, width])\n",
        "    y_min, x_min, y_max, x_max = box.numpy().astype(int)\n",
        "\n",
        "    cv.rectangle(output_image, (x_min, y_min), (x_max, y_max), color=(0, 0, 255))\n",
        "    cv.putText(\n",
        "   output_image,\n",
        "   text=\"dog\",\n",
        "   org=(x_min, y_min),\n",
        "   fontFace=cv.FONT_HERSHEY_SIMPLEX,\n",
        "   fontScale=1,\n",
        "   color=(0, 0, 255),\n",
        ")\n",
        "cv.imwrite(\"output.jpg\", output_image)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[18.  3.  3.  3.  1.  3. 18. 34.  1. 56. 56. 90.  3. 62.  3. 64. 64. 43.\n",
            "  2.  1. 18. 18. 31. 38. 27.  3. 34.  1. 56.  1.  2.  3. 43.  3. 18.  3.\n",
            "  1.  3.  2. 27. 31.  3.  1. 56. 27.  8. 64. 28. 84. 34. 90.  8. 15. 64.\n",
            " 64.  1. 64.  1. 64. 90. 63.  1.  3. 17. 84. 62.  1. 34. 62.  1.  6. 21.\n",
            " 64.  3. 38. 18.  2. 28. 18.  1. 17. 84. 28. 38. 67.  3.  2. 27. 15. 84.\n",
            " 64. 31.  1.  3. 43. 43.  3. 64.  1. 25.], shape=(100,), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MblVC5-Yy9qd",
        "outputId": "4c144afb-b38f-43a6-ed3e-301bd386d082"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3193, done.\u001b[K\n",
            "remote: Counting objects: 100% (3193/3193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2697/2697), done.\u001b[K\n",
            "remote: Total 3193 (delta 848), reused 1382 (delta 453), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3193/3193), 33.39 MiB | 28.09 MiB/s, done.\n",
            "Resolving deltas: 100% (848/848), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0-tTEvLy-xl",
        "outputId": "2ee0f8f1-4a77-4a36-d176-82ac54084af1"
      },
      "source": [
        "!pip install protobuf-compiler"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf-compiler\n",
            "  Downloading protobuf_compiler-1.0.20-py3-none-any.whl (8.6 kB)\n",
            "Collecting bleach==2.1.0\n",
            "  Downloading bleach-2.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting colorama==0.3.3\n",
            "  Downloading colorama-0.3.3.tar.gz (22 kB)\n",
            "Collecting tqdm==4.31.1\n",
            "  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting grpcio==1.18.0\n",
            "  Downloading grpcio-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 8.6 MB/s \n",
            "\u001b[?25hCollecting grpcio-tools==1.18.0\n",
            "  Downloading grpcio_tools-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (22.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.8 MB 110.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from protobuf-compiler) (1.1.0)\n",
            "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /usr/local/lib/python3.7/dist-packages (from bleach==2.1.0->protobuf-compiler) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bleach==2.1.0->protobuf-compiler) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.5.0.post1 in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.18.0->protobuf-compiler) (3.17.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach==2.1.0->protobuf-compiler) (0.5.1)\n",
            "Building wheels for collected packages: colorama\n",
            "  Building wheel for colorama (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colorama: filename=colorama-0.3.3-py3-none-any.whl size=14331 sha256=83e6aadd4742322adcc9711b628c83c9c55ab7e808571cb9395d90bb0b7ea647\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/42/97/77eb85865f435ca81a91fe4c269471f5b4d50144344868f3b1\n",
            "Successfully built colorama\n",
            "Installing collected packages: grpcio, tqdm, grpcio-tools, colorama, bleach, protobuf-compiler\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: bleach\n",
            "    Found existing installation: bleach 4.1.0\n",
            "    Uninstalling bleach-4.1.0:\n",
            "      Successfully uninstalled bleach-4.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0 requires grpcio<2.0,>=1.24.3, but you have grpcio 1.18.0 which is incompatible.\n",
            "tensorboard 2.7.0 requires grpcio>=1.24.3, but you have grpcio 1.18.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "Successfully installed bleach-2.1 colorama-0.3.3 grpcio-1.18.0 grpcio-tools-1.18.0 protobuf-compiler-1.0.20 tqdm-4.31.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAbYHwTZ0e74",
        "outputId": "5ca449f2-f7c2-4d4f-e6b8-40625367e517"
      },
      "source": [
        "!cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!pip install -q ."
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object_detection/protos/*.proto: No such file or directory\n",
            "cp: cannot stat 'object_detection/packages/tf2/setup.py': No such file or directory\n",
            "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}